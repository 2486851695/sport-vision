<div align="center">

# âš¡ Sport Vision

**AI-powered motion recognition for racket sports**

å®æ—¶éª¨éª¼è¿½è¸ª Â· å‡»çƒåŠ¨ä½œè¯†åˆ« Â· è¿åŠ¨ç”Ÿç‰©åŠ›å­¦åˆ†æ

[![License: MIT](https://img.shields.io/badge/License-MIT-cyan.svg)](LICENSE)
[![Python 3.9+](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://python.org)
[![MediaPipe](https://img.shields.io/badge/MediaPipe-PoseLandmarker-green.svg)](https://ai.google.dev/edge/mediapipe)

</div>

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ¦´ **Real-time Pose Tracking** | MediaPipe PoseLandmarker with 13 keypoints |
| ğŸ¯ **Action Recognition** | Serve, Smash, Forehand, Backhand, Lob, Drop |
| ï¿½ **Biomechanics Analysis** | Joint angles, wrist speed, body lean, symmetry |
| ğŸ”¥ **Movement Heatmap** | Spatial visualization of player movement |
| âš¡ **Action Timeline** | Sequential recording of all detected actions |
| ğŸŒ **Real-time WebSocket** | Streaming analysis at ~20 FPS |
| ğŸ¨ **Stunning UI** | Dark neon theme with particle animation |

> **Zero cloud dependency** â€” All AI inference runs locally on CPU. No API keys needed.

## ğŸš€ Quick Start

```bash
# Clone
git clone https://github.com/MindDock/sport-vision.git
cd sport-vision

# One-click start (creates venv, installs deps, downloads model, launches server)
chmod +x run.sh
./run.sh

# Open browser
open http://localhost:8000
```

### Manual Setup

```bash
# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Download pose model
mkdir -p models
curl -sL -o models/pose_landmarker_lite.task \
  "https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/latest/pose_landmarker_lite.task"

# Start server
python -m uvicorn backend.main:app --host 0.0.0.0 --port 8000
```

## ğŸ¬ Usage

1. **Upload a video** â€” Click the upload button and select a badminton/tennis match video
2. **Use demo videos** â€” Place `.mp4` files in the `demo_videos/` directory
3. **Watch the analysis** â€” Real-time skeleton overlay, action recognition, and biomechanics data
4. **Review the timeline** â€” All detected actions are recorded in the action timeline

## ğŸ—ï¸ Architecture

```
Video Input
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Backend                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ MediaPipe     â”‚â†’ 13 Keypoints    â”‚
â”‚  â”‚ PoseLandmarkerâ”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚         â†“                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Action        â”‚  â”‚ Biomechanicsâ”‚  â”‚
â”‚  â”‚ Recognizer    â”‚  â”‚ Analyzer    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â†“                â†“          â”‚
â”‚     WebSocket (JSON + Base64 Frame) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend (Canvas + Dashboard)      â”‚
â”‚  Skeleton Overlay Â· Gauges Â· Heatmapâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
sport-vision/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI server + WebSocket
â”‚   â”œâ”€â”€ pipeline.py           # Video processing pipeline
â”‚   â”œâ”€â”€ pose_analyzer.py      # MediaPipe pose estimation + biomechanics
â”‚   â”œâ”€â”€ action_recognizer.py  # Rule-based action recognition engine
â”‚   â””â”€â”€ visualizer.py         # OpenCV skeleton rendering
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html            # Single-page application
â”‚   â”œâ”€â”€ css/style.css         # Dark neon design system
â”‚   â””â”€â”€ js/
â”‚       â”œâ”€â”€ app.js            # WebSocket client + UI orchestration
â”‚       â”œâ”€â”€ dashboard.js      # Gauges, stats, heatmap rendering
â”‚       â”œâ”€â”€ skeleton-renderer.js  # Canvas skeleton overlay
â”‚       â””â”€â”€ particles.js      # Background particle animation
â”œâ”€â”€ models/                   # MediaPipe model (auto-downloaded)
â”œâ”€â”€ demo_videos/              # Place your .mp4 files here
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run.sh                    # One-click launcher
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-------|-----------|
| Pose Estimation | [MediaPipe PoseLandmarker](https://ai.google.dev/edge/mediapipe/solutions/vision/pose_landmarker) |
| Action Recognition | Rule-based keypoint temporal analysis |
| Video Processing | OpenCV |
| Backend | FastAPI + WebSocket |
| Frontend | Vanilla JS + Canvas API |
| Styling | CSS (dark neon + glassmorphism) |

## ğŸ¤ Contributing

Contributions are welcome! Some ideas:

- [ ] **Improve action recognition** â€” Add ML-based classifier (ST-GCN)
- [ ] **Multi-person tracking** â€” ByteTrack / BoT-SORT integration
- [ ] **3D pose lifting** â€” MotionBERT for 2Dâ†’3D reconstruction
- [ ] **Action quality assessment** â€” Score technique quality
- [ ] **Mobile deployment** â€” CoreML / TFLite export

## ğŸ“„ License

[MIT](LICENSE) Â© [MindDock](https://github.com/MindDock)
